# DataFixter 工程开发待办事项

## 项目概述
DataFixter 是一个用于处理监测数据Excel文件的工具，主要功能是验证和修正监测数据中的累计变化量计算逻辑，确保数据的连续性和准确性。

## 核心需求分析

### 1. 数据源要求
- **输入目录1**: 需要处理的数据文件夹（包含所有监测期数据）
  - 路径: `E:\workspace\gmdi\tools\WorkPartner\excel\processed`
- **输入目录2**: 对比数据文件夹（用于验证和参考）
  - 路径: `E:\workspace\gmdi\tools\WorkPartner\excel`
- **文件格式**: 仅支持 .xls 格式（使用NPOI库读取）

### 2. Excel文件结构
- **数据起始行**: 第5行开始
- **数据结束行**: 第364行（共360行数据）
- **列结构**（从左至右）:
  1. 序号
  2. 点名（唯一标识）
  3. 里程
  4. 本期变化量（X）
  5. 本期变化量（Y）
  6. 本期变化量（Z）
  7. 累计变化量（X）
  8. 累计变化量（Y）
  9. 累计变化量（Z）
  10. 日变化量（X）
  11. 日变化量（Y）
  12. 日变化量（Z）

### 3. 文件命名规则
- 格式: `{日期}-{时}{项目名称}.xls`
- 示例: `2024-01-15-08项目A.xls`
- 文件按时间顺序排列，每期数据行数一致

### 4. 数据逻辑规则
- **基本公式**: 累计变化量 = 上一期累计变化量 + 本期变化量
- 适用于X、Y、Z三个方向的变化量

### 5. 数据处理流程
1. 读取所有Excel文件
2. 按点名分组
3. 按时间排序
4. 验证数据逻辑
5. 标记异常数据
6. 统一处理修正

### 6. 数据修正规则
- **优先级**: 优先调整本期变化量
- **本期变化量限制**: 调整后绝对值不能超过1
- **累计变化量限制**: 绝对值不能超过4
- **修正策略**: 从前往后逐期修正，注意前后期衔接
- **最小化原则**: 尽量减少修改的行数

### 7. 数据统计和报告要求
- **处理前统计**: 输出不合格数据占比（按点名统计）
- **处理后统计**: 输出每个点号调整数据的占比
- **统计维度**: 按点名、按文件、按调整类型分类统计
- **报告格式**: 仅在命令行输出，不生成其他格式文件

## 开发任务清单

### 阶段1: 项目基础搭建
- [ ] 添加NPOI NuGet包依赖
- [ ] 添加Serilog NuGet包依赖
- [ ] 创建项目配置文件
- [ ] 设置Serilog日志记录系统
- [ ] 创建异常处理机制
- [ ] 创建基础项目结构
- [ ] 设置单元测试框架

### 阶段2: 数据模型设计
- [ ] 搭建数据模型基础框架
- [ ] 创建监测点数据模型类（MonitoringPoint）
- [ ] 创建单期数据模型类（PeriodData）
- [ ] 创建文件信息模型类（FileInfo）
- [ ] 创建数据验证结果模型类（ValidationResult）
- [ ] 创建数据统计模型类（DataStatistics）
- [ ] 创建调整记录模型类（AdjustmentRecord）
- [ ] 编写数据模型单元测试
- [ ] 重构数据模型代码
- [ ] 验证重构后的测试通过

### 阶段3: Excel读取功能
- [ ] 搭建Excel读取基础框架
- [ ] 实现Excel文件读取器（ExcelReader）
- [ ] 支持.xls格式文件读取
- [ ] 实现从第5行到第364行的数据提取
- [ ] 实现文件名解析（日期、时间、项目名称）
- [ ] 实现文件按时间排序功能
- [ ] 编写Excel读取单元测试
- [ ] 重构Excel读取代码
- [ ] 验证重构后的测试通过

### 阶段4: 数据验证逻辑
- [ ] 搭建数据验证基础框架
- [ ] 实现按点名分组功能
- [ ] 实现按时间排序功能
- [ ] 实现累计变化量计算逻辑验证
- [ ] 实现与对比数据的交叉验证
- [ ] 实现异常数据标记功能
- [ ] 实现数据质量统计功能（不合格数据占比）
- [ ] 实现按点名、按文件的异常数据统计
- [ ] 编写数据验证单元测试
- [ ] 重构数据验证代码
- [ ] 验证重构后的测试通过

### 阶段5: 数据修正算法
- [ ] 搭建数据修正基础框架
- [ ] 实现本期变化量调整算法
- [ ] 实现累计变化量调整算法
- [ ] 实现前后期衔接验证
- [ ] 实现最小化修改策略
- [ ] 实现修正结果验证
- [ ] 实现调整记录跟踪功能
- [ ] 实现调整后数据统计功能（调整数据占比）
- [ ] 编写数据修正单元测试
- [ ] 重构数据修正代码
- [ ] 验证重构后的测试通过

### 阶段6: 输出和报告
- [ ] 搭建输出报告基础框架
- [ ] 实现修正后的Excel文件生成
- [ ] 实现命令行报告输出功能
- [ ] 实现异常数据汇总报告
- [ ] 实现处理统计信息
- [ ] 实现处理前数据质量统计报告
- [ ] 实现处理后调整数据统计报告
- [ ] 实现按点名、按文件、按调整类型的分类统计
- [ ] 实现统计报告的命令行格式化输出
- [ ] 编写输出报告单元测试
- [ ] 重构输出报告代码
- [ ] 验证重构后的测试通过

### 阶段7: 用户界面和配置
- [ ] 搭建命令行界面基础框架
- [ ] 实现命令行参数解析
- [ ] 实现目录路径验证（使用指定的Excel目录）
- [ ] 实现配置文件支持
- [ ] 实现进度显示功能
- [ ] 编写命令行界面单元测试
- [ ] 重构命令行界面代码
- [ ] 验证重构后的测试通过

## 开发流程规范

### 1. 阶段开发原则
- **基础优先**: 每个阶段必须先搭建好基础框架
- **测试驱动**: 每个阶段必须通过测试后才能进入下一阶段
- **重构要求**: 进入下一阶段前必须重构当前代码并通过测试
- **任务更新**: 每完成一个任务必须更新待办事项

### 2. 开发阶段流程
1. **基础搭建**: 创建项目结构、添加依赖、设置测试框架
2. **功能实现**: 实现当前阶段的核心功能
3. **单元测试**: 编写并运行单元测试，确保功能正确
4. **代码重构**: 重构代码，提高代码质量和可维护性
5. **测试验证**: 重构后再次运行测试，确保功能正常
6. **任务更新**: 更新待办事项，标记已完成任务
7. **进入下一阶段**: 开始下一阶段的开发

## 技术实现要点

### 1. 日志系统要求
- 使用Serilog作为日志框架
- 支持结构化日志记录
- 支持多种输出目标（文件、控制台、数据库等）
- 支持日志级别配置和过滤

### 2. NPOI使用注意事项
- 使用HSSFWorkbook处理.xls文件
- 注意内存管理，及时释放资源
- 处理可能的文件损坏情况

### 2. 数据验证策略
- 建立数据完整性检查
- 实现增量式验证（逐期验证）
- 处理缺失数据的情况

### 3. 修正算法设计
- 使用回溯算法确保修正的连续性
- 实现约束条件检查
- 优化算法性能，减少不必要的计算

### 4. 错误处理
- 文件读取错误处理
- 数据格式错误处理
- 修正失败的回滚机制

## 测试策略

### 1. 测试数据要求
- **必须使用真实Excel文件进行测试**
- **待处理数据目录**: `E:\workspace\gmdi\tools\WorkPartner\excel\processed`
- **对比数据目录**: `E:\workspace\gmdi\tools\WorkPartner\excel`
- 所有功能测试必须基于上述目录中的实际Excel文件

### 2. 单元测试
- 项目基础框架测试
- 数据模型测试
- Excel读取功能测试
- 数据验证逻辑测试
- 修正算法测试
- 数据统计功能测试
- 报告生成功能测试
- 用户界面功能测试

### 2. 集成测试
- 完整数据处理流程测试（使用指定Excel目录）
- 大文件处理性能测试
- 异常情况处理测试
- 真实Excel文件处理测试

### 3. 用户验收测试
- 真实Excel数据验证（使用指定目录）
- 修正结果准确性验证
- 性能指标验证
- 命令行输出质量验证

## 性能要求

### 1. 处理能力
- 支持单次处理100+个Excel文件
- 单文件处理时间不超过30秒
- 内存使用控制在合理范围内

### 2. 输出质量
- 修正后的数据逻辑一致性100%
- 修正幅度最小化
- 保持原始数据格式和结构
- 统计报告准确性100%
- 命令行报告输出清晰易读

## 风险评估

### 1. 技术风险
- NPOI库的兼容性问题
- 大文件处理的内存问题
- 修正算法的准确性风险

### 2. 业务风险
- 数据修正可能影响历史数据连续性
- 修正规则可能不适用于所有情况
- 对比数据质量依赖风险

## 后续优化方向

### 1. 功能扩展
- 支持.xlsx格式
- 支持更多数据验证规则
- 支持自定义修正策略
- 支持自定义统计维度
- 支持更多日志输出目标
- 支持日志配置热更新

### 2. 性能优化
- 并行处理多个文件
- 缓存机制优化
- 增量处理支持

### 3. 用户体验
- 命令行界面简洁易用
- 实时进度显示
- 详细的命令行处理报告
- 实时日志显示
- 日志级别动态调整
